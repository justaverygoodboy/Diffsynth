#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import torch
import os
import argparse
import time
from pathlib import Path
from datetime import datetime
from diffsynth import save_video, VideoData
from diffsynth.pipelines.wan_video_new import WanVideoPipeline, ModelConfig
from tqdm import tqdm
import multiprocessing as mp
from queue import Queue
import threading

def read_prompt_list(prompt_file):
    """è¯»å–promptåˆ—è¡¨æ–‡ä»¶"""
    with open(prompt_file, 'r', encoding='utf-8') as f:
        prompts = [line.strip() for line in f.readlines() if line.strip()]
    return prompts

def create_output_filename(prompt, index, output_dir):
    """åˆ›å»ºè¾“å‡ºæ–‡ä»¶å"""
    # ã€ä¿®æ”¹ã€‘ç®€åŒ–æ–‡ä»¶åï¼Œé¿å…promptè¿‡é•¿é—®é¢˜
    filename = f"wan2.1_1.3B_{index:04d}.mp4"
    return os.path.join(output_dir, filename)

def setup_pipeline(model_id, device_id=0):
    """è®¾ç½®WANè§†é¢‘ç”Ÿæˆç®¡é“"""
    print(f"Setting up pipeline on GPU {device_id}...")
    
    # è®¾ç½®CUDAè®¾å¤‡
    torch.cuda.set_device(device_id)
    device = f"cuda:{device_id}"
    
    pipe = WanVideoPipeline.from_pretrained(
        torch_dtype=torch.bfloat16,
        device=device,
        model_configs=[
            ModelConfig(model_id=model_id, origin_file_pattern="diffusion_pytorch_model.safetensors", offload_device="cpu"),
            ModelConfig(model_id=model_id, origin_file_pattern="models_t5_umt5-xxl-enc-bf16.pth", offload_device="cpu"),
            ModelConfig(model_id=model_id, origin_file_pattern="Wan2.1_VAE.pth", offload_device="cpu"),
        ],
    )
    pipe.enable_vram_management()
    
    print(f"âœ… Pipeline ready on GPU {device_id}")
    return pipe

def generate_single_video(pipe, prompt, output_file, args, device_id):
    """ç”Ÿæˆå•ä¸ªè§†é¢‘"""
    try:
        # ã€ä¿®æ”¹ã€‘æ˜¾ç¤ºå®Œæ•´promptï¼Œä¸è£å‰ª
        print(f"[GPU {device_id}] Generating: {prompt}")
        
        # ã€ä¿®æ”¹ã€‘ä½¿ç”¨å®Œæ•´çš„promptï¼Œä¸åšä»»ä½•å¤„ç†
        video = pipe(
            prompt=prompt,  # å®Œæ•´prompt
            negative_prompt=args.negative_prompt,
            seed=args.seed + hash(prompt) % 10000,  # åŸºäºpromptçš„hashç”Ÿæˆä¸åŒseed
            tiled=args.tiled,
            height=args.height,
            width=args.width,
            num_frames=args.num_frames,
        )
        
        # ä¿å­˜è§†é¢‘
        save_video(video, output_file, fps=args.fps, quality=args.quality)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
        if os.path.exists(output_file):
            file_size = os.path.getsize(output_file) / (1024 * 1024)  # MB
            print(f"[GPU {device_id}] âœ… Generated: {output_file} ({file_size:.1f}MB)")
            return True
        else:
            print(f"[GPU {device_id}] âŒ File not created: {output_file}")
            return False
            
    except Exception as e:
        print(f"[GPU {device_id}] ğŸ’¥ Error generating video: {e}")
        return False

def worker_process(gpu_id, prompt_queue, result_queue, args):
    """å·¥ä½œè¿›ç¨‹å‡½æ•°"""
    try:
        # è®¾ç½®ç®¡é“
        pipe = setup_pipeline(args.model_id, gpu_id)
        
        success_count = 0
        total_count = 0
        
        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
                item = prompt_queue.get(timeout=5)
                if item is None:  # ç»“æŸä¿¡å·
                    break
                
                prompt_index, prompt = item
                total_count += 1
                
                # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
                output_file = create_output_filename(prompt, prompt_index, args.output_dir)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                if os.path.exists(output_file):
                    print(f"[GPU {gpu_id}] File exists, skipping: {output_file}")
                    success_count += 1
                    success = True
                else:
                    # ç”Ÿæˆè§†é¢‘
                    success = generate_single_video(pipe, prompt, output_file, args, gpu_id)
                    if success:
                        success_count += 1
                
                # ã€ä¿®æ”¹ã€‘è¿”å›ç»“æœæ—¶æ˜¾ç¤ºå®Œæ•´prompt
                result_queue.put({
                    'gpu_id': gpu_id,
                    'index': prompt_index,
                    'prompt': prompt,  # å®Œæ•´prompt
                    'output_file': output_file,
                    'success': success
                })
                
            except Exception as e:
                print(f"[GPU {gpu_id}] Worker error: {e}")
                break
        
        print(f"[GPU {gpu_id}] Worker finished. Success: {success_count}/{total_count}")
        
    except Exception as e:
        print(f"[GPU {gpu_id}] Worker setup failed: {e}")

def batch_generate_videos(args):
    """æ‰¹é‡ç”Ÿæˆè§†é¢‘çš„ä¸»å‡½æ•°"""
    # è¯»å–promptåˆ—è¡¨
    print(f"Reading prompts from: {args.prompt_file}")
    prompts = read_prompt_list(args.prompt_file)
    print(f"Found {len(prompts)} prompts")
    
    if args.max_prompts > 0:
        prompts = prompts[:args.max_prompts]
        print(f"Limited to {len(prompts)} prompts")
    
    # ã€ä¿®æ”¹ã€‘ç¡®ä¿è¾“å‡ºç›®å½•ä¸º gen_istock
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åˆ›å»ºé˜Ÿåˆ—
    prompt_queue = mp.Queue()
    result_queue = mp.Queue()
    
    # å°†promptsæ”¾å…¥é˜Ÿåˆ—
    for i, prompt in enumerate(prompts):
        prompt_queue.put((i, prompt))
    
    # æ·»åŠ ç»“æŸä¿¡å·
    for _ in range(args.num_gpus):
        prompt_queue.put(None)
    
    # å¯åŠ¨å·¥ä½œè¿›ç¨‹
    print(f"Starting {args.num_gpus} worker processes...")
    processes = []
    for gpu_id in range(args.num_gpus):
        p = mp.Process(target=worker_process, args=(gpu_id, prompt_queue, result_queue, args))
        p.start()
        processes.append(p)
        print(f"Started worker process for GPU {gpu_id}")
        time.sleep(2)  # é¿å…åŒæ—¶åˆå§‹åŒ–æ¨¡å‹
    
    # ç›‘æ§è¿›åº¦
    completed = 0
    success_count = 0
    start_time = time.time()
    
    print(f"\n{'='*80}")
    print(f"Starting video generation...")
    print(f"{'='*80}")
    
    while completed < len(prompts):
        try:
            result = result_queue.get(timeout=300)
            completed += 1
            if result['success']:
                success_count += 1
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            elapsed = time.time() - start_time
            avg_time = elapsed / completed
            eta = avg_time * (len(prompts) - completed)
            
            # ã€ä¿®æ”¹ã€‘æ˜¾ç¤ºå®Œæ•´promptï¼Œä½†é™åˆ¶æ˜¾ç¤ºé•¿åº¦ä»¥é¿å…ç»ˆç«¯æ··ä¹±
            display_prompt = result['prompt']
            if len(display_prompt) > 80:
                display_prompt = display_prompt[:77] + "..."
            
            print(f"Progress: {completed:4d}/{len(prompts)} ({completed/len(prompts)*100:5.1f}%) "
                  f"Success: {success_count:4d} "
                  f"ETA: {eta/60:6.1f}min "
                  f"[GPU {result['gpu_id']}] {display_prompt}")
            
        except Exception as e:
            print(f"Error monitoring progress: {e}")
            break
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    print("\nWaiting for all processes to finish...")
    for p in processes:
        p.join(timeout=600)
        if p.is_alive():
            print(f"Force terminating process {p.pid}")
            p.terminate()
            p.join()
    
    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    total_time = time.time() - start_time
    print(f"\n{'='*80}")
    print(f"Batch generation completed!")
    print(f"{'='*80}")
    print(f"Total prompts: {len(prompts)}")
    print(f"Successful: {success_count}")
    print(f"Failed: {len(prompts) - success_count}")
    print(f"Success rate: {success_count/len(prompts)*100:.1f}%")
    print(f"Total time: {total_time/60:.1f} minutes")
    print(f"Average time per video: {total_time/len(prompts):.1f} seconds")
    print(f"Output directory: {args.output_dir}")
    
    # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
    generated_files = list(Path(args.output_dir).glob("wan2.1_1.3B_*.mp4"))
    print(f"Generated {len(generated_files)} video files")

def main():
    parser = argparse.ArgumentParser(description='Batch video generation using Wan2.1-T2V-1.3B')
    
    # è¾“å…¥è¾“å‡º
    parser.add_argument('--prompt_file', 
                       default='/gemini/platform/public/zqni/istock_output/istock_copied_short.txt',
                       help='Path to the prompt list file')
    parser.add_argument('--output_dir', default='/gemini/platform/public/zqni/istock_output/istock_gen',  # ã€ä¿®æ”¹ã€‘é»˜è®¤è¾“å‡ºç›®å½•
                       help='Output directory for generated videos')
    parser.add_argument('--model_id', default='Wan-AI/Wan2.1-T2V-1.3B',
                       help='Model ID for WAN pipeline')
    
    # GPUè®¾ç½®
    parser.add_argument('--num_gpus', type=int, default=8,
                       help='Number of GPUs to use')
    parser.add_argument('--max_prompts', type=int, default=-1,
                       help='Maximum number of prompts to process (-1 for all)')
    
    # ç”Ÿæˆå‚æ•°
    parser.add_argument('--height', type=int, default=480,
                       help='Video height')
    parser.add_argument('--width', type=int, default=832,
                       help='Video width')
    parser.add_argument('--num_frames', type=int, default=81,
                       help='Number of frames')
    parser.add_argument('--fps', type=int, default=25,
                       help='Frames per second')
    parser.add_argument('--quality', type=int, default=5,
                       help='Video quality (1-10)')
    parser.add_argument('--seed', type=int, default=42,
                       help='Base seed for generation')
    parser.add_argument('--tiled', action='store_true', default=True,
                       help='Use tiled generation')
    
    # Promptè®¾ç½®
    parser.add_argument('--negative_prompt', 
                       default="è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
                       help='Negative prompt for generation')
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥
    if not os.path.exists(args.prompt_file):
        print(f"Error: Prompt file not found: {args.prompt_file}")
        return 1
    
    # æ£€æŸ¥GPUæ•°é‡
    available_gpus = torch.cuda.device_count()
    if args.num_gpus > available_gpus:
        print(f"Warning: Requested {args.num_gpus} GPUs, but only {available_gpus} available")
        args.num_gpus = available_gpus
    
    print(f"Configuration:")
    print(f"  Prompt file: {args.prompt_file}")
    print(f"  Output directory: {args.output_dir}")
    print(f"  Model ID: {args.model_id}")
    print(f"  Number of GPUs: {args.num_gpus}")
    print(f"  Video size: {args.width}x{args.height}")
    print(f"  Frames: {args.num_frames}")
    print(f"  FPS: {args.fps}")
    print(f"  Quality: {args.quality}")
    print("")
    
    # å¼€å§‹æ‰¹é‡ç”Ÿæˆ
    try:
        batch_generate_videos(args)
        return 0
    except KeyboardInterrupt:
        print("\nInterrupted by user")
        return 1
    except Exception as e:
        print(f"Error: {e}")
        return 1

if __name__ == '__main__':
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    mp.set_start_method('spawn', force=True)
    exit(main())